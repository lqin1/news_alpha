{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization,LeakyReLU,Dropout,Average\n",
    "from keras.losses import binary_crossentropy, mse, mae\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mkt_url = 'raw/small_market.csv'\n",
    "news_url = 'raw/small_newsdata.csv'\n",
    "\n",
    "market_dtypes = {\n",
    "    'assetCode': str,\n",
    "    'assetName': str,\n",
    "    'volume': float,\n",
    "    'close': float,\n",
    "    'open': float,\n",
    "    'returnsClosePrevRaw1': float,\n",
    "    'returnsOpenPrevRaw1': float,\n",
    "    'returnsClosePrevMktres1': float,\n",
    "    'returnsOpenPrevMktres1': float,\n",
    "    'returnsClosePrevRaw10': float,\n",
    "    'returnsOpenPrevRaw10': float,\n",
    "    'returnsClosePrevMktres10': float,\n",
    "    'returnsOpenPrevMktres10': float,\n",
    "    'returnsOpenNextMktres10': float,\n",
    "    'universe': float\n",
    "}\n",
    "market_date_cols = ['time']\n",
    "\n",
    "news_dtypes = {\n",
    "    'sourceId': str,\n",
    "    'headline': str,\n",
    "    'urgency': int,\n",
    "    'takeSequence': int,\n",
    "    'provider': str,\n",
    "    'subjects': str,\n",
    "    'audiences': str,\n",
    "    'bodySize': int,\n",
    "    'companyCount': int,\n",
    "    'headlineTag': str,\n",
    "    'marketCommentary': bool,\n",
    "    'sentenceCount': int,\n",
    "    'wordCount': int,\n",
    "    'assetCodes': str,\n",
    "    'assetName': str,\n",
    "    'firstMentionSentence': int,\n",
    "    'relevance': float,\n",
    "    'sentimentClass': int,\n",
    "    'sentimentNegative': float,\n",
    "    'sentimentNeutral': float,\n",
    "    'sentimentPositive': float,\n",
    "    'sentimentWordCount': int,\n",
    "    'noveltyCount12H': int,\n",
    "    'noveltyCount24H': int,\n",
    "    'noveltyCount3D': int,\n",
    "    'noveltyCount5D': int,\n",
    "    'noveltyCount7D': int,\n",
    "    'volumeCounts12H': int,\n",
    "    'volumeCounts24H': int,\n",
    "    'volumeCounts3D': int,\n",
    "    'volumeCounts5D': int,\n",
    "    'volumeCounts7D': int}\n",
    "news_date_cols = ['time', 'sourceTimestamp', 'firstCreated', ]\n",
    "\n",
    "df_market_orig = pd.read_csv(mkt_url, dtype=market_dtypes, parse_dates=market_date_cols)\n",
    "df_news_orig = pd.read_csv(news_url, dtype=news_dtypes, parse_dates=news_date_cols)\n",
    "\n",
    "cat_cols = ['assetCode']\n",
    "num_cols = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1',\n",
    "                    'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10',\n",
    "                    'returnsOpenPrevMktres10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(df_market_orig.index.values,test_size=0.3)\n",
    "train_indices.shape, val_indices.shape\n",
    "df_market_train = df_market_orig.loc[train_indices]\n",
    "df_market_val = df_market_orig.loc[val_indices]\n",
    "# train_indices.shape, df_market_train.shape, val_indices.shape, df_market_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_market_orig.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding assetCode\n"
     ]
    }
   ],
   "source": [
    "def encode(encoder, x):\n",
    "    len_encoder = len(encoder)\n",
    "    try:\n",
    "        ind = encoder[x]\n",
    "    except KeyError:\n",
    "        ind = len_encoder\n",
    "    return ind\n",
    "\n",
    "encoders = [{} for cat in cat_cols]\n",
    "\n",
    "for i, cat in enumerate(cat_cols):\n",
    "    print('encoding %s'%cat, end='\\n')\n",
    "    encoders[i] = {l:ind for ind, l in enumerate(df_market_train[cat].unique())}\n",
    "    df_market_train[cat] = df_market_train[cat].apply(lambda x:encode(encoders[i],x))\n",
    "    df_market_val[cat] = df_market_val[cat].apply(lambda x:encode(encoders[i],x))\n",
    "    \n",
    "embed_sizes = [len(encoder) + 1 for encoder in encoders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lqin/github/news_alpha/.env/lib/python3.6/site-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/lqin/github/news_alpha/.env/lib/python3.6/site-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_market_train[num_cols] = df_market_train[num_cols].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "df_market_train[num_cols] = scaler.fit_transform(df_market_train[num_cols])\n",
    "df_market_val[num_cols] = scaler.fit_transform(df_market_val[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_inputs = []\n",
    "for cat in cat_cols:\n",
    "    cat_inputs.append(Input(shape=[1], name=cat))\n",
    "    \n",
    "cat_embs = []\n",
    "for i,cat in enumerate(cat_cols):\n",
    "    cat_embs.append(Embedding(embed_sizes[i], 10)(cat_inputs[i]))\n",
    "\n",
    "cat_logits = Flatten()(cat_embs[0])\n",
    "cat_logits = Dense(32)(cat_logits)\n",
    "cat_logits = LeakyReLU(0.1)(cat_logits)\n",
    "cat_logits = Dropout(0.5)(cat_logits)\n",
    "num_input = Input(shape = (len(num_cols),), name='num')\n",
    "num_logits = num_input\n",
    "num_logits = BatchNormalization()(num_logits)\n",
    "num_logits = Dense(32)(num_logits)\n",
    "num_logits = LeakyReLU(0.1)(num_logits)\n",
    "num_logits = Dropout(0.5)(num_logits)\n",
    "all_logits = Concatenate()([num_logits, cat_logits])\n",
    "logits = Dense(128, activation='relu')(all_logits)\n",
    "logits = Dropout(0.5)(logits)\n",
    "logits = Dense(64, activation='relu')(logits)\n",
    "logits = Dropout(0.5)(logits)\n",
    "out = Dense(1, activation='tanh')(logits)\n",
    "\n",
    "model = Model(inputs = cat_inputs+[num_input],outputs=out)\n",
    "model.compile(optimizer='adam', loss=mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31    0\n",
       "13    0\n",
       "45    0\n",
       "55    0\n",
       "78    0\n",
       "     ..\n",
       "71    0\n",
       "65    0\n",
       "33    0\n",
       "83    0\n",
       "87    0\n",
       "Name: returnsOpenNextMktres10, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_market_train.head()\n",
    "\n",
    "df_market_train[num_cols].values.shape\n",
    "df_market_train['returnsOpenNextMktres10'].apply(lambda x:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(df):\n",
    "    X_num = df[num_cols].values\n",
    "    X = {'num':X_num}\n",
    "    for cat in cat_cols:\n",
    "        X[cat] = df[cat].values\n",
    "    df['returnsOpenNextMktres10'] = df['returnsOpenNextMktres10'].apply(lambda x: 0 if x < -0.3 or x > 0.3 else x)\n",
    "    df['returnsOpenNextMktres10'] = df['returnsOpenNextMktres10'].apply(lambda x: -1 if x < 0 else x)\n",
    "    df['returnsOpenNextMktres10'] = df['returnsOpenNextMktres10'].apply(lambda x: 1 if x > 0 else x)\n",
    "    y = df['returnsOpenNextMktres10'].values\n",
    "    r = df['returnsOpenNextMktres10'].values\n",
    "    u = df['universe']\n",
    "    d = df['time'].dt.date\n",
    "    return X,y,r,u,d\n",
    "    \n",
    "# r, u and d are used to calculate the scoring metric\n",
    "X_train,y_train,r_train,u_train,d_train = get_input(df_market_train)\n",
    "X_valid,y_valid,r_valid,u_valid,d_valid = get_input(df_market_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[ 1.14933317e-01, -2.03341265e-01, -2.13043470e-01,\n         4.05538088e-01,  1.24931597e+00,  0.00000000e+00,\n         0.00000000e+00, -1.04794978e+00, -1.07033907e+00,\n         0.00000000e+0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-325eca459427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/news_alpha/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/news_alpha/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/news_alpha/.env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[ 1.14933317e-01, -2.03341265e-01, -2.13043470e-01,\n         4.05538088e-01,  1.24931597e+00,  0.00000000e+00,\n         0.00000000e+00, -1.04794978e+00, -1.07033907e+00,\n         0.00000000e+0..."
     ]
    }
   ],
   "source": [
    "X_train['num'].shape\n",
    "model.fit(X_train['num'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-dbd82d8b21c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpredictions_template_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_template_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confidenceValue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'confidence'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'confidenceValue'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_template_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "days = () # TODO\n",
    "n_days = 0\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    n_days += 1\n",
    "    if n_days % 10 == 0:\n",
    "        print(n_days,end='\\n')\n",
    "    # num features\n",
    "    market_obs_df[num_cols] = market_obs_df[num_cols].fillna(0)\n",
    "    market_obs_df[num_cols] = scaler.transform(market_obs_df[num_cols])\n",
    "    X_num_test = market_obs_df[num_cols].values\n",
    "    X_test = {'num':X_num_test}\n",
    "    for i in range(len(cat_cols)):\n",
    "        market_obs_df[cat_cols[i]+'_encoded'] = market_obs_df[cat_cols[i]].astype(str).apply(lambda x: encode(encoders[i], x))\n",
    "        X_test[cat_cols[i]] = market_obs_df[cat_cols[i]+'_encoded']\n",
    "    market_prediction = model.predict(X_test)\n",
    "    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'], 'confidence':market_prediction.reshape(-1)})\n",
    "    predictions_template_df = predictions_template_df.merge(preds, how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "    env.predict(predictions_template_df)\n",
    "env.write_submission_file()\n",
    "print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
